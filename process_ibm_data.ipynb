{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import qiskit\n",
    "from qiskit.transpiler import Layout\n",
    "from qiskit.opflow.state_fns import DictStateFn\n",
    "from qiskit.opflow import I, X, Y, Z, CircuitOp, StateFn\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_ibm_provider import IBMProvider\n",
    "# IBMProvider.save_account(\"700663709ad0eadb905450245f20e3e363ef30b27fb5971bc4544567711e8458b187869d5882e5bc2134ec6a0ed07014ae50e0b344b8b1556022d0de348f4447\", overwrite=True)\n",
    "# provider = IBMProvider()\n",
    "# print(provider.backends())\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "from qiskit.algorithms import VQE, QAOA, NumPyMinimumEigensolver\n",
    "from qiskit.algorithms.optimizers import COBYLA, SPSA, SLSQP\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import AerPauliExpectation, PauliExpectation, StateFn, DictStateFn, CircuitStateFn, Z\n",
    "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "from qiskit_optimization.applications import Maxcut, SKModel\n",
    "# from qiskit_optimization.translators import from_docplex_mp\n",
    "from qiskit.utils import algorithm_globals\n",
    "# from docplex.mp.model import Model\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit.quantum_info.analysis import hellinger_fidelity\n",
    "\n",
    "from qiskit.converters import circuit_to_dag\n",
    "\n",
    "from oscar.utils import maxcut_obj, obj_from_statevector, get_adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_energy(G, qc: QuantumCircuit=None, cnts: dict=None):\n",
    "    # print(qc)\n",
    "    # qc.save_statevector()\n",
    "    shots = 1024\n",
    "    obj = partial(maxcut_obj, w=get_adjacency_matrix(G))\n",
    "    if cnts == None:\n",
    "        backend = AerSimulator(method=\"statevector\")\n",
    "        cnts = backend.run(qc, shots=shots).result().get_counts()\n",
    "\n",
    "    obj_val = 0.0\n",
    "    for bitstring, cnt in cnts.items():\n",
    "        bitstring_int = np.array(list(map(int, list(bitstring))))\n",
    "        obj_val += obj(bitstring_int) * (cnt / shots)\n",
    "        \n",
    "    return obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--gamma-steps'], dest='gamma_steps', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--problem\", type=str, default=\"maxcut\")\n",
    "parser.add_argument(\"-n\", type=int, default=16)\n",
    "parser.add_argument(\"-p\", type=int, default=1)\n",
    "parser.add_argument(\"-s\", \"--seed\", type=int, required=True)\n",
    "parser.add_argument(\"-b\", \"--backend\", type=str, default=\"sv\")\n",
    "parser.add_argument(\"--ansatz\", type=str, default=\"qaoa\")\n",
    "parser.add_argument(\"--cpu\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"--no-aer\", dest=\"aer\", default=True, action=\"store_false\")\n",
    "parser.add_argument(\"--noise\", type=str, default=\"ideal\")\n",
    "parser.add_argument(\"--p1\", type=float, default=0.001)\n",
    "parser.add_argument(\"--p2\", type=float, default=0.005)\n",
    "parser.add_argument(\"--beta-steps\", type=int, default=50)\n",
    "parser.add_argument(\"--gamma-steps\", type=int, default=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ibm_data(ibm_id: int, seed: int, shots: int):\n",
    "    if shots == 2048:\n",
    "        path = f\"figs/ibm/IBM_Exp_2048/IBM-M{ibm_id}/Experimental_Data,Seed-{seed}P=1circ_param_lst_2048.pkl\"\n",
    "        recon_save_dir = \"figs/ibm/IBM_Exp_2048\"\n",
    "    elif shots == 1024:\n",
    "        path = f\"figs/ibm/Experiments/IBM-M{ibm_id}/Experimental_Data,Seed-{seed}P=1circ_param_lst.pkl\"\n",
    "        recon_save_dir = \"figs/ibm/Experiments\"\n",
    "    else:\n",
    "        raise ValueError(\"shots must be 1024 or 2048\")\n",
    "        \n",
    "    print(f\"read from IBM={ibm_id}, seed={seed}\")\n",
    "    file = open(path, 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    cnts_list = data[0]\n",
    "    transpiled_circ = data[1][0]\n",
    "\n",
    "    return cnts_list, transpiled_circ, recon_save_dir\n",
    "\n",
    "\n",
    "def diff(a: dict, b: dict, type: str):\n",
    "    diff = 0.0\n",
    "    if type == 'kl':\n",
    "        P = dict2arr(a)\n",
    "        Q = dict2arr(b)\n",
    "        diff = kl_div(P, Q)\n",
    "    elif type == 'hellinger_fidelity':\n",
    "        diff = hellinger_fidelity(a, b)\n",
    "    elif type == 'tvd':\n",
    "        P = dict2arr(a)\n",
    "        Q = dict2arr(b)\n",
    "        diff = total_variation_distance(P, Q)\n",
    "    return diff\n",
    "    # return norm_between_two_dist_in_dict_form(a, b)\n",
    "\n",
    "\n",
    "def kl_div(P, Q):\n",
    "    return np.sum(np.where(P * Q != 0, P * np.log(P / Q), 0))\n",
    "    \"\"\" Epsilon is used here to avoid conditional code for\n",
    "    checking that neither P nor Q is equal to 0. \"\"\"\n",
    "    # epsilon = 0.00001\n",
    "\n",
    "    # # # You may want to instead make copies to avoid changing the np arrays.\n",
    "    # P = P + epsilon\n",
    "    # Q = Q + epsilon\n",
    "\n",
    "    # divergence = np.sum(P * np.log(P / Q))\n",
    "    # return divergence\n",
    "\n",
    "\n",
    "def dict2arr(dist_dict: dict):\n",
    "    num_qubits = len(next(iter(dist_dict)))\n",
    "    arr = np.zeros(2 ** num_qubits)\n",
    "    shots = np.sum(list(dist_dict.values()))\n",
    "    # print(\"shots=\", shots)\n",
    "    for bitstring, cnt in dist_dict.items():\n",
    "        idx = int(bitstring, 2)\n",
    "        arr[idx] = 1.0 * cnt / shots\n",
    "    assert np.isclose(arr.sum(), 1.0)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def norm_between_two_dist_in_dict_form(a: dict, b: dict):\n",
    "    norm = 0.0\n",
    "    intersection = a.keys() & b.keys()\n",
    "    for key in intersection:\n",
    "        norm += (a[key] - b[key])**2\n",
    "\n",
    "    for key in a.keys() - b.keys():\n",
    "        norm += a[key] ** 2\n",
    "\n",
    "    for key in b.keys() - a.keys():\n",
    "        norm += b[key] ** 2\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "def total_variation_distance(p, q):\n",
    "    return 0.5 * np.sum(np.abs(p - q))\n",
    "\n",
    "MID_TO_DEVICE_NAME = {\n",
    "    1: 'ibm_perth',\n",
    "    2: 'ibm_lagos',\n",
    "}\n",
    "def get_fname(mid: int, seed: int, noise: str):\n",
    "    bs = 50\n",
    "    gs = 100\n",
    "    n = 6\n",
    "    p = 1\n",
    "    problem = \"maxcut\"\n",
    "\n",
    "    assert noise in ['ideal_sim', 'noisy_sim', 'real']\n",
    "    device_name = MID_TO_DEVICE_NAME[mid]\n",
    "    fname = f\"{problem}-{device_name}-{noise}-{n=}-{p=}-{seed=}-{bs}-{gs}\"\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_landscape_from_transpiled_circ(args, ibm_id: int, qcs: QuantumCircuit, exp_val_type: str):\n",
    "    print(args.__dict__)\n",
    "    n = args.n\n",
    "    p = args.p\n",
    "    seed = args.seed\n",
    "    backend_config = args.backend.lower()\n",
    "    noise = args.noise.lower()\n",
    "\n",
    "    device = \"CPU\" if args.cpu else \"GPU\"\n",
    "    backend_config += f\" {noise}\"\n",
    "\n",
    "    if noise == 'ideal_sim':\n",
    "        noise_model = None\n",
    "    elif noise == 'noisy_sim':\n",
    "        provider = IBMProvider()\n",
    "        ibm_device = MID_TO_DEVICE_NAME[ibm_id]\n",
    "        noise_model = NoiseModel.from_backend(provider.get_backend(ibm_device))\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Noise {noise} not implemented yet\")\n",
    "\n",
    "    backend = AerSimulator(\n",
    "        method=\"statevector\",\n",
    "        device=device,\n",
    "        noise_model=noise_model,\n",
    "        fusion_enable=args.problem == \"maxcut\" or noise != \"depolar\" or n < 17,\n",
    "    )\n",
    "    backend_config = backend_config.replace(\" \", \"-\")\n",
    "\n",
    "    # --------------- define the problem ------------\n",
    "\n",
    "    G = nx.random_regular_graph(3, n, seed)\n",
    "    problem = Maxcut(G).to_quadratic_program()\n",
    "    H, offset = problem.to_ising()\n",
    "\n",
    "    algorithm_globals.random_seed = seed\n",
    "\n",
    "    # TODO: you might need to modify this to config IBM backend\n",
    "    # quantum_instance = QuantumInstance(\n",
    "    #     backend=backend,\n",
    "    #     seed_simulator=seed,\n",
    "    #     seed_transpiler=seed,\n",
    "    #     optimization_level=None,\n",
    "    # )\n",
    "\n",
    "    # algorithm = QAOA(\n",
    "    #     SPSA(),\n",
    "    #     reps=p,\n",
    "    #     quantum_instance=quantum_instance,\n",
    "    #     expectation=AerPauliExpectation() if args.aer else None,\n",
    "    # )\n",
    "    # algorithm._check_operator_ansatz(H)\n",
    "    # energy_evaluation, expectation = algorithm.get_energy_evaluation(\n",
    "    #     H, return_expectation=True\n",
    "    # )\n",
    "\n",
    "    # ------------- transpile ----------------\n",
    "    # def energy_evaluation_transpiled(parameters: np.ndarray) -> float:\n",
    "    #     qc = quantum_instance.transpile(algorithm.ansatz.bind_parameters(parameters))[0]\n",
    "    #     observable_meas = expectation.convert(StateFn(H, is_measurement=True))\n",
    "    #     expect_op = observable_meas.compose(CircuitStateFn(qc)).reduce()\n",
    "    #     sampled_expect_op = algorithm._circuit_sampler.convert(expect_op)\n",
    "    #     return np.real(sampled_expect_op.eval())\n",
    "\n",
    "    # energy_evaluation = energy_evaluation_transpiled\n",
    "\n",
    "\n",
    "    dirpath = f\"figs/ibm/{args.ansatz}/{args.problem}/{backend_config}-{p=}\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    # savepath = f\"{dirpath}/{args.problem}-{backend_config}-{n=}-{p=}-{seed=}-{args.beta_steps}-{args.gamma_steps}-IBM{ibm_id}-transpiled-{exp_val_type}\"\n",
    "    savepath = f\"{dirpath}/{get_fname(ibm_id, seed, noise)}\"\n",
    "\n",
    "    if os.path.exists(f\"{savepath}.npz\"):\n",
    "        data = np.load(\n",
    "            f\"{savepath}.npz\",\n",
    "            allow_pickle=True\n",
    "        )\n",
    "\n",
    "        return data['cnts_list'], data['data'], G, offset, H, dict(data)\n",
    "    \n",
    "\n",
    "    # ------------- prepare parameters and execute the circuit --------------\n",
    "    data = []\n",
    "    beta_bound = np.pi / 4 / p\n",
    "    gamma_bound = np.pi / 2 / p\n",
    "\n",
    "    grid = np.array(\n",
    "        np.meshgrid(\n",
    "            *np.linspace([-beta_bound] * p, [beta_bound] * p, args.beta_steps, axis=1),\n",
    "            *np.linspace([-gamma_bound] * p, [gamma_bound] * p, args.gamma_steps, axis=1),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    tmp = grid.transpose((*range(1, 2 * p + 1), 0)).reshape(-1, 2 * p)\n",
    "    observable_meas = H\n",
    "    # observable_meas = Z^6\n",
    "    cnts_list = []\n",
    "    for qc in tqdm(qcs): # transpiled circuit\n",
    "        if exp_val_type == 'H':\n",
    "            job = backend.run(qc, shots=2048)\n",
    "            cnts = job.result().get_counts()\n",
    "            # for bitstring, cnt in cnts.items():\n",
    "            #     cnts[bitstring] = np.sqrt(cnt / 1024.0)\n",
    "            cnts_list.append(cnts)\n",
    "            qc = DictStateFn(job.result())\n",
    "            exp_val = (~qc @ observable_meas @ qc).eval().real\n",
    "        elif exp_val_type == 'graph':\n",
    "            exp_val = get_energy(graph, qc)\n",
    "        elif exp_val_type == 'test':\n",
    "            exp_val = 0\n",
    "        else:\n",
    "            raise NotImplementedError(f\"exp_val_type {exp_val_type} not implemented yet\")\n",
    "            \n",
    "        data.append(exp_val)\n",
    "\n",
    "        # observable_meas = expectation.convert(StateFn(H, is_measurement=True))\n",
    "        # expect_op = observable_meas.compose(qc) # .reduce()\n",
    "        # sampled_expect_op = algorithm._circuit_sampler.convert(expect_op)\n",
    "        # energy = np.real(sampled_expect_op.eval())\n",
    "        # energy = energy_evaluation(params) # ! execute the circuit\n",
    "        # data.append(energy) \n",
    "\n",
    "    data = np.array(data).reshape(([args.beta_steps] * p) + ([args.gamma_steps] * p))\n",
    "\n",
    "    # ----------- save the data ---------\n",
    "    data_dict = {\n",
    "        \"data\": data,\n",
    "        \"offset\": offset,\n",
    "        \"beta_bound\": beta_bound,\n",
    "        \"gamma_bound\": gamma_bound,\n",
    "        \"grid\": grid,\n",
    "        \"cnts_list\": cnts_list\n",
    "    }\n",
    "\n",
    "    np.savez_compressed(\n",
    "        savepath,\n",
    "        # data=data,\n",
    "        # offset=offset,\n",
    "        # beta_bound=beta_bound,\n",
    "        # gamma_bound=gamma_bound,\n",
    "        # grid=grid,\n",
    "        # cnts_list=cnts_list,\n",
    "        **data_dict,\n",
    "        **args.__dict__,\n",
    "    )\n",
    "\n",
    "    return cnts_list, data, G, offset, H, data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ls(G, cnts_list):\n",
    "    ls = []\n",
    "    for cnts in cnts_list:\n",
    "        pt = get_energy(G, None, cnts)\n",
    "        ls.append(pt)\n",
    "\n",
    "    return np.array(ls).reshape((50, 100))\n",
    "\n",
    "def get_ls_by_H(cnts_list, H):\n",
    "    ls = []\n",
    "    \n",
    "    for cnts in cnts_list:\n",
    "        primitive = {\n",
    "            bstr: math.sqrt(shots / sum(cnts.values())) for (bstr, shots) in cnts.items()\n",
    "        }\n",
    "        qc = DictStateFn(primitive)\n",
    "        exp_val = (~qc @ H @ qc).eval().real # < \\psi | H | \\psi >, compose()\n",
    "        ls.append(exp_val)\n",
    "\n",
    "    return np.array(ls).reshape((50, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check difference between counts\n",
    "\n",
    "def vis():\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(15, 12))\n",
    "    axs = axs.reshape(-1)\n",
    "    idx = 0\n",
    "    i = 0\n",
    "    axs[i].imshow(ibm_ls)\n",
    "    axs[i].set_title(\"IBM, bstr\")\n",
    "\n",
    "    axs[i+1].imshow(ibm_H_ls)\n",
    "    axs[i+1].set_title(\"IBM, H\")\n",
    "\n",
    "    axs[i+2].imshow(sim_cnt_ls)\n",
    "    axs[i+2].set_title(\"Sim., bstr\")\n",
    "    \n",
    "    im = axs[i+3].imshow(sim_H_ls)\n",
    "    axs[i+3].set_title(\"Sim., H\")\n",
    "    \n",
    "    vis_path = f\"{save_path}-vis\"\n",
    "    # if not os.path.exists(vis_path):\n",
    "    #     os.makedirs(vis_path)\n",
    "    plt.savefig(vis_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def rebuild_ibm_landscapes(ibm: int, seed: int, tcircs: List[QuantumCircuit]):\n",
    "    is_cnt_cx = False\n",
    "    is_graph_cost = True\n",
    "\n",
    "    \n",
    "    if is_cnt_cx:\n",
    "        n_cx = 0\n",
    "        for tcirc in tcircs:\n",
    "            dag = circuit_to_dag(tcirc)\n",
    "            # print(tcirc)\n",
    "            for node in dag.topological_op_nodes():\n",
    "                if node.name == 'cx':\n",
    "                    n_cx += 1\n",
    "\n",
    "        n_cx /= len(tcircs) * 1.0\n",
    "        print(n_cx)\n",
    "    \n",
    "    # for noise in ['ideal_sim', 'noisy_sim']:\n",
    "    for noise in ['ideal_sim']:\n",
    "        cmd = f\"-n 6 -p 1 --seed {seed} --noise {noise} --cpu --backend {MID_TO_DEVICE_NAME[ibm]} --ansatz qaoa\"\n",
    "        args = parser.parse_args(list(cmd.split(' ')))\n",
    "        sim_cnts_list, ls, G, offset, H, data_dict = generate_landscape_from_transpiled_circ(args, ibm, tcircs, 'H')\n",
    "        \n",
    "        if False:\n",
    "            norm = 0.0\n",
    "            for a, b in zip(ibm_cnts_list, sim_cnts_list):\n",
    "            # for a, b in zip(sim_cnts_list, ibm_cnts_list):\n",
    "                norm += diff(a, b, 'hellinger_fidelity')\n",
    "                # norm += diff(a, b, 'tvd')\n",
    "            norm /= len(ibm_cnts_list)\n",
    "            print(\"norm =\", norm)\n",
    "    \n",
    "        # if False:\n",
    "        ibm_ls = - get_ls(G, ibm_cnts_list)\n",
    "        ibm_H_ls = get_ls_by_H(ibm_cnts_list, H)\n",
    "\n",
    "        sim_cnt_ls = - get_ls(G, sim_cnts_list)\n",
    "        sim_H_ls = get_ls_by_H(sim_cnts_list, H)\n",
    "        # sim_H_ls = (ls + offset)\n",
    "        print(f\"offset={offset}\")\n",
    "        \n",
    "        # save_path = f\"{save_dir}/ls-M-{ibm}-seed-{seed}-{noise}\"\n",
    "        save_dir = f\"figs/ibm/qaoa/maxcut\"\n",
    "        save_path = f\"{save_dir}/{get_fname(ibm, seed, 'real')}\"\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            save_path,\n",
    "            data=ibm_H_ls,\n",
    "            offset=data_dict[\"offset\"],\n",
    "            beta_bound=data_dict[\"beta_bound\"],\n",
    "            gamma_bound=data_dict[\"gamma_bound\"],\n",
    "            grid=data_dict[\"grid\"],\n",
    "            cnts_list=data_dict[\"cnts_list\"],\n",
    "\n",
    "            # ibm_bstr_ls=ibm_ls,\n",
    "            # ibm_H_ls=ibm_H_ls,\n",
    "\n",
    "            # sim_bstr_ls=sim_cnt_ls,\n",
    "            # sim_H_ls=sim_H_ls\n",
    "        )\n",
    "\n",
    "        lss = {\n",
    "            \"ibm_bstr_ls\": ibm_ls,\n",
    "            \"ibm_H_ls\": ibm_H_ls,\n",
    "            \"sim_bstr_ls\": sim_cnt_ls,\n",
    "            \"sim_H_ls\": sim_H_ls\n",
    "        }\n",
    "\n",
    "        return lss    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read from IBM=1, seed=1\n"
     ]
    }
   ],
   "source": [
    "ibm = 1\n",
    "seed = 1\n",
    "shots = 2048\n",
    "ibm_cnts_list, tcircs, save_dir = load_ibm_data(ibm, seed, shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problem': 'maxcut', 'n': 6, 'p': 1, 'seed': 1, 'backend': 'ibm_perth', 'ansatz': 'qaoa', 'cpu': True, 'aer': True, 'noise': 'ideal_sim', 'p1': 0.001, 'p2': 0.005, 'beta_steps': 50, 'gamma_steps': 100}\n",
      "offset=-4.5\n"
     ]
    }
   ],
   "source": [
    "lss = rebuild_ibm_landscapes(ibm, seed, tcircs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# # check there is no difference between ibm_H_ls\n",
    "\n",
    "def check(mid: int, seed: int, noise: str):\n",
    "    fname = get_fname(mid, seed, noise)\n",
    "    a = lss['ibm_H_ls']\n",
    "    # a = np.load(f\"figs/ibm/IBM_Exp_2048/{fname}.npz\")['data']\n",
    "    # ideal = np.load(\"figs/ibm/IBM_Exp_2048/ls-M-1-seed-1-ideal.npz\")['ibm_H_ls']\n",
    "    # perth = np.load(\"figs/ibm/IBM_Exp_2048/ls-M-1-seed-1-ibm_perth.npz\")['ibm_H_ls']\n",
    "    # b = np.load(f\"figs/ibm/qaoa/maxcut/{MID_TO_DEVICE_NAME[mid]}-{noise}-p=1/{fname}.npz\")['data']\n",
    "    b = np.load(f\"figs/ibm/qaoa/maxcut/{fname}.npz\", allow_pickle=True)['data']\n",
    "\n",
    "    print(np.abs(a - b).sum())\n",
    "    # print(np.allclose(a, b))\n",
    "\n",
    "check(ibm, seed, 'real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM 1: 32, 1.2%\n",
    "# IBM 2: largos, 32, 1%\n",
    "# IBM 3: aslow, coherence time is 1/3 of 1 & 2\n",
    "\n",
    "import random\n",
    "norm = 0.0\n",
    "n_tries = 5000\n",
    "n_qubits = 6\n",
    "shots = 1024\n",
    "for i in range(n_tries):\n",
    "\n",
    "    aa = [random.randint(0, 2 ** n_qubits - 1) for _ in range(shots)]\n",
    "    bb = [random.randint(0, 2 ** n_qubits - 1) for _ in range(shots)]\n",
    "\n",
    "    a = np.zeros(2 ** n_qubits)\n",
    "    b = np.zeros(2 ** n_qubits)\n",
    "\n",
    "    for i in aa:\n",
    "        # print(i)\n",
    "        a[i] += 1\n",
    "    \n",
    "    for i in bb:\n",
    "        b[i] += 1\n",
    "    \n",
    "    # a = np.maximum(a, 0)\n",
    "    # b = np.maximum(b, 0)\n",
    "    # a += a.min()\n",
    "    # b += b.min()\n",
    "\n",
    "    a /= shots\n",
    "    b /= shots\n",
    "    norm += kl_div(a, b)\n",
    "\n",
    "norm /= n_tries\n",
    "\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "sfs = [0.01, 0.03, 0.05, 0.07, 0.09]\n",
    "for ibm in ibm_ids:\n",
    "    for seed in seeds: # three instances\n",
    "        if ibm == 3 and seed == 1:\n",
    "            continue\n",
    "\n",
    "        path = f\"figs/grid_search_recon/ibm/machine-{ibm}/recon_error_mid={ibm}-n=6-seed={seed}-sfs=[0.01 0.03 0.05 0.07 0.09]-error=NRMSE.npz\"\n",
    "        recon_error_data = np.load(path, allow_pickle=True)\n",
    "        sfs = recon_error_data['sfs']\n",
    "        mses = recon_error_data['mses']\n",
    "        plt.plot(sfs, mses, label=f\"M{ibm}, seed {seed}\")\n",
    "plt.ylabel(\"NRMSE\")\n",
    "plt.xlabel(\"Sampling fraction\")\n",
    "# plt.suptitle(\"NRMSE\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cfe83fec8e00998f88dcc564f097010aa405553f21e6b5ff9b1f81004a6f146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
